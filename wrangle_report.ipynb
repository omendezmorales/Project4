{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle and Analyze Data report #\n",
    "By Orlando Mendez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the summary of experiences about my data wrangling project for the Udacity nano degree on Data Analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The gathering step ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, I had to assemble a master dataset from three sources:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _one csv file (WeRateDogs Twitter archive)_. This file was downloaded manually.\n",
    "* _one tsv file (tweet image predictions)_. This file was downloaded programmatically using the `requests` module\n",
    "* _one txt file (containing json data)_. From this file I had to pull at a minimum the tweet's id, retweet count, and favorite (\"like\") count. To download his file required me to communicate via the Twitter API via the `tweepy` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all the steps above, the first two were easy to get. For the third however, I had to try a couple of times, since my access tokens apparently expired (I was getting error  code 89 described [here](https://github.com/ttezel/twit/issues/204)). Finally, I succeded to downlad the data in a text file as requested.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The assesing step ##\n",
    "\n",
    "Once the source files are downloaded, I assesed them both programmatically and visually. I have to acknowledge that classifyng the issues into either quality or tidiness was not exactly easy for some (e.g. some columns helped me to decide some rows had to be removed, but was this issue a quality one or a tidiness one, or both?). I may need to exercise further in order to become familiar with the type of issue.\n",
    "\n",
    "Further, this was perhaps the most time consuming step of them all (I reckon ~40% of the total time spent for this project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cleaning step\n",
    "\n",
    "This part was done again one dataframe at a time. I learnt from the lessons in the course it is a good practice to make a copy of the original dataframes prior to start cleaning (and saving time plus some headhaches by doing so!).\n",
    "\n",
    "From the efforts done in this step, the hardest was for me to melt four columns of the archive enhanced dataframe ( `doggo, floofer, pupper,  puppo`) into one (`stage`). The verification was easy, though (as the sum of the former four columns should match the value of the latter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
